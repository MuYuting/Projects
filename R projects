library(DBI)
library(data.table)
library(RSQLite)
library(blscrapeR)
library(ggplot2)

con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')


#Q1
wage1 <- data.table(dbReadTable(con,'wage1'))

#1
mean(wage1$educ)## The average eduaction level 
min(wage1$educ)## The lowest years of eductaion level 
max(wage1$educ)## The highest years of eductaion level 

#2
mean(wage1$wage)##The average hourly wage, It seems low.

#3
df <- bls_api("CUSR0000SA0")
head(df, 5)
da <- inflation_adjust(1976)
tail(da)
dc <- inflation_adjust(2010)
tail(dc)
dc <- data.table(dc)
head(dc)

#4
mean(dc$avg_cpi)## average hourly wage in 2010

#5
sum(wage1$female == 1)##women
sum(wage1$female == 0)##men



#Q2
meap01 <- data.table(dbReadTable(con,'meap01'))

#1.
min(meap01$math4)## The largest values of math4
max(meap01$math4)## The smallest values of math4
#Does the range make sense? 
#The largest and smallest values are the highest and lowest score, so this result does not make sense.

#2
#Assume the pass score for math is 60
sum(meap01$math4==100)
sum(meap01$math4>=0)##Amount of all samples
38/1823
##What percentage is this of the total samples

#3
sum(meap01$math4==50)##Math pass rates of exactly 50%

#4
summary(meap01$math4)
summary(meap01$read4)
#The mean and median scores of math both are higher than read, so read test is harder to pass.

#5
cor(meap01$math4, meap01$read4)##The correlation between math4 and read4

#6
mean(meap01$exppp)##Average of exppp
sd(meap01$exppp)##Standard deviation of exppp

#7
(6000-5500)/5500##What percentage does School A's spending exceed School B's
log_percentage<-100*(log(6000)-log(5500))
summary(log_percentage)
(0.091-0.087)/0.087
#Approximation percentage difference



#Q3
r401k <- data.table(dbReadTable(con,'401k'))

#1
mean(r401k$prate)
mean(r401k$mrate)

#2
r401kreg <- lm(data = r401k, prate~mrate)
summary(r401kreg)

#3
#the intercept means when mrate=0, the participaton rate will still be 83.07%. 
#The coefficient means that whenever the match rate increase 1, the paticipation rate will increase 5.86%

#4
#since y=ax+b, when mrate=3.5, prate=
83.0755 + 5.6*(3.5)
# it is not a reasonable prediction since the maximum of prate is 100
#this is caused by a dependent variable are bounded, the regression model may produce an unreasonable number for the independent variable

#5
#the mrate explains around 0.075 of prate.



#Q4
ceosal2 <- data.table(dbReadTable(con,'ceosal2'))

#1
mean(ceosal2$salary)#average salary
mean(ceosal2$ceoten)#average tenure

#2
nrow(filter(ceosal2, ceoten==0))# first year as CEO 
max(ceosal2$ceoten)#e longest tenure as a CEO

#3
summary(lm(log(salary) ~ ceoten, data=ceosal2))
# the (approximate) predicted percentage increase in salary is  given one more year as a CEO




#Q5
wage2 <- data.table(dbReadTable(con,'wage2'))

#1
mean(wage2$wage)#average salary
mean(wage2$IQ)#average IQ 
sd(wage2$IQ)#standard deviation of IQ

#2
summary(lm(data = wage2, wage~IQ))# simple regression model
8.30*15#the predicted increase in wage for an increase in IQ of 15 points is
#R-squared=0.09554
#IQ can explain 9.5% variation in wage

#3
summary(lm(data = wage2, log(wage)~IQ))#model
15*0.0088
#IQ increases by 15 points, 13.2% increase in predicted wage



#Q6
meap93 <- data.table(dbReadTable(con,'meap93'))

#1
cor(meap93$math10, meap93$expend)##The correlation between math10 pass rate and expend.
#The expend with math pass rate have positive correlation relationship, but it's not strong.

#2
#B1 is a log, and present as percentage form, math10 also have a percentage form. so B1*(10/100)

#3
summary(lm(data = meap93, math10~log(expend)))

#4
summary(lm(data = meap93, math10~log(expend)))##line model between math10 and expend
#This relationship means when math10 increases 11.164%, the expend will increase by 100%.
(0.11164*0.1)*100
#If give a 10% increase in spending,the math10 will increase by 1.1164%.

#5
summary(meap93$math10)
#In this data set,this is not much a worry since except math10 there also have two other variables improves. That will be a balance. 



#Q7
hprice1 <- data.table(dbReadTable(con,'hprice1'))

#1
summary( lm(price ~ sqrft + bdrms, data=hprice1))
#Equation: price=-19.315+0.12844(sqrft)+15.19819(bdrms)+u

#2 
#The estimated increase in price when holding square footage constant and a house with one more bedroom is:
15.19819*1000


#3
# the estimated increase in price for a house with an additional bedroom that is 140 square feet in size
(0.12844 * 140 + 15.19819 * 1) *1000




#Q8
ceosal2 <- data.table(dbReadTable(con,'ceosal2'))

#1
summary(lm(log(salary)~log(sales)+log(mktval), data=ceosal2))
#Equation:
#log(salary)=4.62092+0.16213(sales)+0.10671(mktval)

#2
summary(lm(log(salary)~log(sales)+log(mktval)+profits, data=ceosal2))
#profits cannot be included in logarithmic form, because log of a negative value because it is undefined
#I would not say that these firm performance variables explain most of the variation in CEO salaries
#because R-squared is 0.2993 and there are around 70% of salary are unexplained

#3
summary(lm(log(salary)~log(sales)+log(mktval)+profits+ceoten, data=ceosal2))
#log(salary) = 4.558 + 0.1622log(sales) + 0.1018log(mktval) + 0.00prof its +0.01168ceoten 
0.01168*100
#the estimated percentage return for another year of CEO tenure is 1.168%  holding other factors fixed

#4
cor(log(ceosal2$mktval),ceosal2$profits)
#The sample correlation coefficient between the variables log(mktval) and profits is 77.68976%.they are highly correlated.
#both of these variable should be included in the equation in order to avoid omitted-variable bias
#4 
#R-squared=0.6319. So 63.19% of the variation in price is explained by square footage and number of bedrooms

#5
# the predicted selling price for this house from the OLS regression line is:
(-19.315 + 0.12844 * 2438 + 15.19819 * 4)*1000

#6
#the residual for this house is:
(300-(-19.32 + 0.12844 * 2438 + 15.19819 * 4))*1000
#it does suggest that the buyer underpaid for the house






#Q9
attend <- data.table(dbReadTable(con,'attend'))

#1
summary(attend$atndrte)##Min6.25; Max100; Mean81.71
summary(attend$priGPA)##Min0.857; Max3.930; Mean2.587
summary(attend$ACT)##Min13; Max32; Mean22.51

#2
#priGPA/termGPA?
summary(lm(data = attend, atndrte~priGPA+ACT))
#In equation form, atndrte=75.7+17.261priGPA-1.717ACT
#In this data set I believe this have not a useful meaning.  
#The attend rate will be 75.7% if the priGPA and ACT both are 0 that have not universal because almost no student will have priGPA=0, and ACT=0.

#3
#When ACT score goes up, the attend rate goes down. That make me surprises.

#4
priGPA<-3.65
ACT<-20
atndrte<-75.7+17.261*priGPA-1.717*ACT
atndrte
#There no student with these values.

#5
priGPA_a<-3.1
ACT_a<-21
atndrte_a<-75.7+17.261*priGPA_a-1.717*ACT_a
priGPA_b<-2.1
ACT_b<-26
atndrte_b<-75.7+17.261*priGPA_b-1.717*ACT_b
atndrte_a-atndrte_b



#Q10
htv <- data.table(dbReadTable(con,'htv'))

#1
#The educ range is:
max(htv$educ)-min(htv$educ)
#percentage of men completed 12th grade is but no higher grade:
mean(htv$educ==12)
#men have, on average, higher levels of education than their parents:
summary(htv[,.(educ,motheduc,fatheduc)])

#2
summary(lm(educ~motheduc+fatheduc,data=htv))
#educ= 6.96435 + 0.30420motheduc+ 0.19029fatheduc
#The sample variation in educ is explained by parents' education is:
#R-squared:  0.2493*100%=24.93%
#Every one year of motheduc increase 1, their sone get 0.30420*100=30.42% more year of education

#3
summary(lm(educ~motheduc+fatheduc+abil,data=htv))
#Educ=  8.44869 + 0.18913motheduc+ 0.11109fatheduc+ 0.50248abil
#R-squared increase from 0.2493 to 0.4275. Ability does help to explain variations in education

#4
abil.sq <- htv$abil^2
model<-lm(educ~motheduc+fatheduc+abil+abil.sq,data=htv)
summary(model)
#The equation is:
#educ=8.240226+0.190126motheduc+0.108939fatheduc+0.401462abil+0.050599abil^2
# the value of abil where educ is minimized which is 0.
#0=0+0+0+0.401462abil+0.050599abil^2
#0=0.401462+0.050599abil*2=
abil.min<--0.401462/0.050599/2
abil.min

#5
mean(htv$abil<=abil.min)
#only 1.2% of men in the sample have ability less than -3.967094.
#It is important, because only a small amount of men have the ability level between -3.967094 to 0.

#6
htv2 <- htv
htv2$motheduc <- as.double(htv2$motheduc)
htv2$fatheduc <- as.double(htv2$fatheduc)
htv2$motheduc <- 12.18
htv2$fatheduc <- 12.45
ggplot(htv, aes(x=abil,y=educ))+geom_point()+geom_line(aes(y=predict(model,htv2)),color="Red")+scale_x_continuous('Ability measure')+scale_y_continuous('Years of education')

--------------------------------
library(data.table)
library(RSQLite)

##Q1
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
vote1 <- data.table(dbReadTable(con,'vote1'))
summary(vote1)
##1
##when every other factors is fixed, every one percentage of campaign expenditure change, 
##the vote will change B1/100percentage points
##2
##The null hypothesis means when expenditures A and B increase the same amount, voteA's number will not change.
##which means B1+B2=0 and B1=- B2
##3
summary(lm(voteA~log(expendA)+log(expendB)+prtystrA,data=vote1))
##The formula is:
##voteA = 45.08788 + 6.08136*ln[expendA] - 6.61563* ln[expendB] + 0.15201
##Both expendA and expendB  will affect the outcome.
##However, we won't able to test the hypothesis with this alone, 
##because we don't have the Std. Error of B1+B2
##4
##β1 = θ1 − β2
##voteA = B0 + O1 ln[expendA] + B2(ln[expendB] − ln[expendA]) + B3prystrA + u,
summary(lm(voteA~log(expendA)+I(log(expendB)-log(expendA))+prtystrA,data=vote1))
##5
## O1=-0.53427, it is insignificant in 10% level 

##Q2
##1
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
lawsch85 <- data.table(dbReadTable(con,'lawsch85'))
model1 <- lm(log(salary)~LSAT+GPA+log(libvol)+log(cost)+rank,data=lawsch85) 
summary(model1)
##The coefficient on rank is -0.003, so that shows the rank of law schools has no ceteris paribus effect on median starting salary.
##2
model <- lm(log(salary)~log(libvol)+log(cost)+rank,data=lawsch85[!is.na(LSAT)]) 
anova(model,model1)
##Yes，tehy are individually significant for salary.
##3
model1 <- lm(log(salary)~LSAT+GPA+log(libvol)+log(cost)+rank,data=lawsch85)
model2 <- lm(log(salary)~LSAT+GPA+log(libvol)+log(cost)+rank+clsize+faculty,data=lawsch85)
c(AIC(model1),BIC(model1))
c(AIC(model2),BIC(model2))
##From the result of two models, the variables are no need to add in. 
##4
##Such as location, student's family income.



##Q3
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
hprice1 <- data.table(dbReadTable(con,'hprice1'))
##1
summary(lm(log(price)~sqrft+bdrms,data=hprice1))
##θ1=
150*3.794e-04+2.888e-02
##2
##B2=θ1-150B1
##ln[price]= B0 + B1sqrf t + (θ1-150B1)bdrms + u.
##ln[price]= B0 + B1*(sqrf-150bdrms)+θ1bdrmS+U
##3
summary(lm(log(price)~I(sqrft-150*bdrms)+bdrms,data=hprice1))
confint(lm(log(price)~I(sqrft-150*bdrms)+bdrms,data=hprice1))
##confidence interval range is [0.0325803714,0.1390223618]
#Therefore, interval = [3.26%, 13.90%]


##Q4
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
wage2 <- data.table(dbReadTable(con,'wage2'))
##1
##The null hypothesis is B2=B3
##Because a year of general workforce experienc and 
##a year of tenure has the  same effect on ln[wage] 
##2
#B2=O1+B3
##ln[wage] = B0 + B1educ + O1exper + B3(tenure + exper) + u.
summary(lm(log(wage)~educ+exper+I(tenure+exper),data=wage2))
##O1's =0.001954 which is insignificance at 5% level.



##Q5
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
table401 <- data.table(dbReadTable(con,'401ksubs'))
##1
summary(table401)
nrow(table401[fsize==1])
##2
summary(lm(nettfa~inc+age,data=table401[fsize==1]))
##nettfa = −43.03981 + 0.79932inc + 0.84266age + u
##The formula means every one more dollar of income ,
##it will have around 80 cents more in wealth,
##his/her age increase 1 year, there wealth will increase 842.66 in wealth.
##There is no surprises in the slope estimates.
##3
##If we keep inc=0(no income), age=0(just born), then,B0=-43.03981=nettfa
##4
##H0:O1+1=B2
##nettfa  = B0 + B1inc + O1age + age + u,
##nettfa - age= B0 + B1inc + O1age + u,
summary(lm(I(nettfa-age)~inc+age,data=table401[fsize==1]))
##H0: P value=0.0874/2=0.0437
##Therefore, the null hypothesis rejected at 1% level of significance.
##5
##part2:
summary(lm(nettfa~inc+age,data=table401[fsize==1]))
##part5
summary(lm(nettfa~inc,data=table401[fsize==1]))
## On part 2, the income's estimated coefficient is 0.79932 and 
##on part 5the income's estimated coefficient is 0.8207. it is not much different.
##because it has a low correlation between income and age for single-person households 


##Q6
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
kielmc <- data.table(dbReadTable(con,'kielmc'))
##1
##Since the presence of the incinerator depresses housing prices
##so I expect a larger distance a higher price the house is, which means B1>0
summary(lm(log(price)~log(dist),data=kielmc[year==1981]))
##ln[price] = 8.04716 + 0.36488 ln[dist]
##This means every 1% increase in distance the house price with increase 0.36488%
##2
summary(lm(log(price)~log(dist)+log(intst)+log(area)+log(land)+rooms+baths+age,data=kielmc[year==1981]))
##The coefficient of log(dist) drops from 0.36488 to 0.055389.
##it  is not significant, because there are a lot more other factors in the formula
##which makes distance is not as important as part1.
##3
summary(lm(log(price)~log(dist)+log(intst)+I(log(intst)^2)+log(area)+log(land)+rooms+baths+age,data=kielmc[year==1981]))
##After adding [intst]^2 to the formula every factor gets more significant
##[intst]^2 performs a important job in the functional form.
##which means further away from interstate lower the price of the house.
##4
summary(lm(log(price)~log(dist)+I(log(dist)^2)+log(intst)+I(log(intst)^2)+log(area)+log(land)+rooms+baths+age,data=kielmc[year==1981]))
##the coefficient of (dist)^2 is -0.036418 and t value is -0.331,
##it is not significant in the formula.


##Q7
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
wage1 <- data.table(dbReadTable(con,'wage1'))
##1
model<-lm(log(wage)~educ+exper+I(exper^2),data=wage1)
summary(model)
##ln[wage] = 0.1263226 + 0.0906207educ + 0.0409731exper -0.0007121exper2 + u
##2
##Yes, exper^2 is statistically significant at the 1% level.
##3
0.0409731-2*(0.0007121)*5
0.0409731-2*(0.0007121)*20
##4
-0.0409731/(2*(0.0007121))
nrow(wage1[exper>28.7692])
##The experience is 28.7692, 121people have more than 28.7692 years experience.



##Q8
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
wage2 <- data.table(dbReadTable(con,'wage2'))
##1
##holding experience fixed
##log(wage) = B1educ + B3educ × exper=(B1 + B3exper)educ
##log(wage)/educ=(B1 + B3exper)
##2
## H0:B3=0, since more experience should have a positive effect on wages
##Therefore, the appropriate alternative should be H1:B3>0
##3
summary(lm(log(wage)~educ+exper+educ:exper,data=wage2))
## p lower than 0.05. Therefore, The we reject H0 against H1 on 5% level.
##4
##The formula is:
##log(wage) = B0 + O1educ + B2exper + B3(educ × exper − 10educ) + u.
summary(lm(log(wage)~educ+exper+I(educ*exper-10*educ),data=wage2))
##O1=0.076080  and confidence interval is 
0.0760795 - 0.0066151 * 1.96
0.0760795 + 0.0066151 * 1.96
##[0.063, 0.089].



##Q9
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
gpa2 <- data.table(dbReadTable(con,'gpa2'))
##1
summary(lm(sat~hsize+I(hsize^2),data=gpa2))
##sat = 997.981 + 19.814hsize − 2.131(hsize^2) + u
##2
##sat = 997.981 + 19.814hsize − 2.131(hsize^2)
##hsize =
19.814/(2*(2.131))
##since hsize is in 100s. the “optimal" high school size will be 465
##3
## This analysis does not representative all high school seniors, 
##it is only representing the high school senior in the table
##4
summary(lm(log(sat)~hsize+I(hsize^2),data=gpa2))
##hsize =
0.0196029/(2*(0.0020872))
##The optimal high school size is 470. it has 5  people difference with part 2.



##Q10
con <- dbConnect(RSQLite::SQLite(),'wooldridge2.db')
hprice1 <- data.table(dbReadTable(con,'hprice1'))
##1
summary(lm(log(price)~log(lotsize)+log(sqrft)+bdrms,data=hprice1))
##The formula will be:
##ln[price] = −1.29704 + 0.16797 ln[lotsize] + 0.70023 ln[sqrft] + 0.03696bdrms + û
##2
##ln[price]=
−1.29704 + 0.16797 *log(20000) + 0.70023 *log(2500) + 0.03696*4
##ln[price]=5.992921, price=400.574
## the predicted value of price is $400574
##3
##Part 1 model:
summary(lm(log(price)~log(lotsize)+log(sqrft)+bdrms,data=hprice1))
##Part 3 model:
summary(lm(price~lotsize+sqrft+bdrms,data=hprice1))
##Part 3 has the high R-squared=0.6724, which means it is a better model.
